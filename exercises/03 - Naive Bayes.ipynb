{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Inhibitors dataset\n",
    "Following dataset is coming from https://www.kaggle.com/xiaotawkaggle/inhibitors\n",
    "\n",
    "On Leho there is an adapted csv of the cdk2.h5 dataset. The adaptations I already did for you was extracting the data out of the .h5 file. Renaming the columns, add in the IDs of each of the compounds (row names) and combine it with the target into a .csv file.\n",
    "\n",
    "For cdk2, 1890 potential inhibitors are collected from chembl database, in which molecules with IC50 lower than 10 uM are usually considered as inhibitors, otherwise non-inhibitors.\n",
    "\n",
    "The rownames represent the CHEMBL Id, which can be used to search the CHEMBL database: https://www.ebi.ac.uk/chembl/\n",
    "\n",
    "The features are split into 3 categories that represent three different sets of molecular fingerprints calculated by RDKIT. For more information: http://www.rdkit.org/docs/GettingStartedInPython.html#topological-fingerprints\n",
    "* ap: Atom Pairs\n",
    "* mg: Morgan Fingerprints (Circular Fingerprints)\n",
    "* tt: Topological Torsions\n",
    "\n",
    "The actual values represent if a molecular fingerprint is present in a specific molecule or not (1: present, 0: not present)\n",
    "\n",
    "The target column indicated if the molecule is considered an inhibitor or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data, because we have row names in our dataset, use pd.read_csv('filename.csv',index_col=0)\n",
    "cdk2_data = pd.read_csv(\"../exercises/data/cdk2.csv\", index_col=0)\n",
    "# Take a look at the first rows of the dataframe\n",
    "cdk2_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the number of rows and columns in the dataframe\n",
    "print(\"rows, columns\", cdk2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the counts of the target column using a seaborn countplot\n",
    "sns.countplot(data=cdk2_data,x=\"target\")\n",
    "# This is a little bit unbalanced, but we will not look at this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a countplot of the first feature column (ap_1)\n",
    "sns.countplot(data=cdk2_data,x=\"ap_1\")\n",
    "# This looks strange, and is not optimal. But, we will leave this like it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is noteworthy of the plot above?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "Due to the amount of columns, a df.describe() will not show you a lot of information.\n",
    "\n",
    "Pairplots and corrplots would be gigantic and also not very informative due to it being sparse data.\n",
    "\n",
    "Removing outliers would not be a good idea, since a lot of the values that are different from 0 would already be considered outliers, whilst these are just the informative things.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and targets\n",
    "X=cdk2_data.drop(\"target\",axis=1)\n",
    "y=cdk2_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set. Keep +-20% as a test_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multinomial naive bayes classifier\n",
    "model = MultinomialNB(alpha=1)\n",
    "\n",
    "# Fit the training data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Show the score of the test data\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Predict values for the test set\n",
    "model.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix and classification report\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,ConfusionMatrixDisplay,recall_score,precision_score,f1_score\n",
    "print(cf:=confusion_matrix(y_test,model.predict(X_test)))\n",
    "matrix = ConfusionMatrixDisplay(cf,display_labels=model.classes_)\n",
    "matrix.plot()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a logistic regression model on the data and test it as you did for the naive bayes model\n",
    "# I had a warning about iterations. max_iter = 100 default. Increasing this parameter will get rid of the warning\n",
    "logReg_model = LogisticRegression(C=1,max_iter=1000) \n",
    "logReg_model.fit(X_train,y_train)\n",
    "print(logReg_model.score(X_test,y_test))\n",
    "logReg_model.predict(X_test)\n",
    "\n",
    "print(cf:=confusion_matrix(y_test,logReg_model.predict(X_test)))\n",
    "matrix = ConfusionMatrixDisplay(cf,display_labels=logReg_model.classes_)\n",
    "matrix.plot()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, logReg_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try and play with the hyperparameters a bit\n",
    "\n",
    "## Conclusion\n",
    "**What can we conclude regarding the metrics of both models**\n",
    "\n",
    "\n",
    "**What can we conclude regarding the time it takes to train the model?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset\n",
    "MNIST is the \"hello world\" of AI.\n",
    "\n",
    "MNIST is a dataset containing a lot of handwritten digits. The goal is to correctly identify the written digit from the image. There is a lot of different sets and subsets available online. The data that we will be using is coming from\n",
    "https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "Each image contains 28x28 pixels => 784 values between 0 (black) and 255 (white)\n",
    "\n",
    "Some initial code is given as to show you how to display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df = pd.read_csv(\"data/MNIST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of the numbers\n",
    "sns.countplot(x=\"label\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and targets\n",
    "X = df.drop(\"label\",axis=1)\n",
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value to see another sample\n",
    "row_num_X = 3\n",
    "\n",
    "# Extract the image from X\n",
    "single_image= X.iloc[row_num_X,:]  ## Row row_num_X, column all (:)\n",
    "\n",
    "# Convert the single array of 784 pixels into nested arrays as to creat a 28x28 array\n",
    "# [p0,p1,p2,p3,...,p784] becomes\n",
    "\n",
    "# [[p0,p1,p2,p3,...,p27]\n",
    "#  [p28,p29,p30,    ...]\n",
    "#  ...\n",
    "#  [          ..., p783]]\n",
    "single_image_to_28x28 = single_image.values.reshape(28,28)\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(single_image_to_28x28,cmap='Greys')\n",
    "# Also print the corresponding label\n",
    "print(f\"Label: {y[row_num_X]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set. Keep +-20% as a test_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train a multinomial naive bayes model on the data and test it using the test data\n",
    "model = MultinomialNB(alpha=1)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_test,y_test))\n",
    "print(model.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values for the test set\n",
    "model.predict(X_test)\n",
    "# Print a confusion matrix and classification report\n",
    "print(cf:=confusion_matrix(y_test,model.predict(X_test)))\n",
    "matrix = ConfusionMatrixDisplay(cf,display_labels=model.classes_)\n",
    "matrix.plot()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before performing logistec regression, scaling the data, because it took to long and took too much itetations, even with warnings\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) # niet op volledige data doen, anders test je geen nieuwe data in je scaler.fit\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Also try it using a logistic regression model\n",
    "model = LogisticRegression(C=1, max_iter=1000)\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Score of the testset:\",model.score(X_test,y_test))\n",
    "print(\"Score of the trainingset:\", model.score(X_train,y_train))\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf:=confusion_matrix(y_test,model.predict(X_test)))\n",
    "matrix = ConfusionMatrixDisplay(cf,display_labels=model.classes_)\n",
    "matrix.plot()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code let's you draw a number and predict it using your model\n",
    "\n",
    "The model should be called 'model' or be renamed in the code below\n",
    "\n",
    "Note that you need packages pillow and tkinter\n",
    "\n",
    "`conda install pillow tk` or `pip3 install pillow tk` or `sudo dnf install python3-pillow python3-tkinter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw, ImageChops\n",
    "import PIL\n",
    "from tkinter import *\n",
    "\n",
    "width = 280  # canvas width\n",
    "height = 280 # canvas height\n",
    "center = height//2\n",
    "white = (255) # canvas back\n",
    "\n",
    "def predict():\n",
    "    op2 = ImageChops.invert(output_image)\n",
    "    op2=op2.resize((28,28),resample=3)\n",
    "    # Show the image\n",
    "    plt.imshow(op2,cmap='Greys')\n",
    "    op2_array = np.asarray(op2).reshape(1,-1)\n",
    "    print(model.predict(op2_array))\n",
    "    \n",
    "def clear():\n",
    "    plt.close()\n",
    "    canvas.delete(\"all\")\n",
    "    draw.rectangle((0,0,width,height),fill=255)\n",
    "    \n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    canvas.create_oval(x1, y1, x2, y2, fill=\"black\",width=25)\n",
    "    draw.line([x1, y1, x2, y2],fill=\"black\",width=25)\n",
    "\n",
    "master = Tk()\n",
    "\n",
    "# create a tkinter canvas to draw on\n",
    "canvas = Canvas(master, width=width, height=height, bg='white')\n",
    "canvas.pack()\n",
    "\n",
    "# create an empty PIL image and draw object to draw on\n",
    "output_image = PIL.Image.new(\"L\", (width, height), white)\n",
    "draw = ImageDraw.Draw(output_image)\n",
    "canvas.pack(expand=YES, fill=BOTH)\n",
    "canvas.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "# add a button to save the image\n",
    "button=Button(text=\"predict\",command=predict)\n",
    "button.pack()\n",
    "button=Button(text=\"clear\",command=clear)\n",
    "button.pack()\n",
    "\n",
    "master.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
