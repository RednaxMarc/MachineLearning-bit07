{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact,widgets                # For interactive execution of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guest/MachineLearning/demos/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv(\"../data/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first lines\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and targets\n",
    "features = data.drop(\"target\",axis=1)\n",
    "target = data[\"target\"]\n",
    "\n",
    "# Split into train and test set (50 test samples)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,target,test_size=50,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.610 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.711 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.790 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.614 total time=   0.1s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l1, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l1, solver=liblinear;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l1, solver=liblinear;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l1, solver=liblinear;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l1, solver=saga;, score=0.828 total time=   0.2s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l1, solver=liblinear;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l1, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l1, solver=liblinear;, score=0.851 total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l1, solver=saga;, score=0.614 total time=   0.2s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l1, solver=saga;, score=0.751 total time=   0.2s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l2, solver=saga;, score=0.614 total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.610 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.557 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.571 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.557 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.675 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.636 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.769 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.810 total time=   0.1s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l1, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l2, solver=saga;, score=0.614 total time=   0.2s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.3s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.790 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l2, solver=newton-cg;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l2, solver=newton-cg;, score=0.815 total time=   0.1s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l2, solver=lbfgs;, score=0.794 total time=   0.2s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l2, solver=lbfgs;, score=0.877 total time=   0.2s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.2s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.2s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.3s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l2, solver=liblinear;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l2, solver=liblinear;, score=0.851 total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=8.894444444444444, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=8.894444444444444, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=8.894444444444444, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END C=8.894444444444444, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=8.894444444444444, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.3s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.3s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "150 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.61757482        nan 0.61757482 0.73625071\n",
      " 0.73625071 0.73982213 0.72677866 0.71684077        nan        nan\n",
      " 0.81661491        nan 0.7196358  0.81304348 0.80947205 0.83265104\n",
      " 0.76475155 0.7196358         nan        nan 0.81758893        nan\n",
      " 0.7196358  0.80590062 0.80590062 0.82985601 0.76475155 0.7196358\n",
      "        nan        nan 0.81758893        nan 0.7196358  0.81044608\n",
      " 0.81044608 0.82628458 0.76475155 0.7196358         nan        nan\n",
      " 0.8140175         nan 0.7196358  0.8147939  0.8147939  0.82193676\n",
      " 0.76475155 0.7196358         nan        nan 0.8140175         nan\n",
      " 0.7196358  0.8147939  0.8147939  0.82193676 0.76475155 0.7196358\n",
      "        nan        nan 0.8140175         nan 0.7196358  0.8147939\n",
      " 0.81044608 0.82193676 0.76475155 0.7196358         nan        nan\n",
      " 0.8140175         nan 0.7196358  0.8147939  0.8140175  0.82193676\n",
      " 0.76475155 0.7196358         nan        nan 0.8140175         nan\n",
      " 0.7196358  0.81836533 0.82271316 0.82193676 0.76475155 0.7196358\n",
      "        nan        nan 0.8140175         nan 0.7196358  0.81836533\n",
      " 0.81836533 0.82193676 0.76475155 0.7196358 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: array([1.00000000e-02, 2.23111111e+00, 4.45222222e+00, 6.67333333e+00,\n",
       "       8.89444444e+00, 1.11155556e+01, 1.33366667e+01, 1.55577778e+01,\n",
       "       1.77788889e+01, 2.00000000e+01]),\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                     &#x27;saga&#x27;]}],\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: array([1.00000000e-02, 2.23111111e+00, 4.45222222e+00, 6.67333333e+00,\n",
       "       8.89444444e+00, 1.11155556e+01, 1.33366667e+01, 1.55577778e+01,\n",
       "       1.77788889e+01, 2.00000000e+01]),\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                     &#x27;saga&#x27;]}],\n",
       "             scoring=&#x27;balanced_accuracy&#x27;, verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid=[{'C': array([1.00000000e-02, 2.23111111e+00, 4.45222222e+00, 6.67333333e+00,\n",
       "       8.89444444e+00, 1.11155556e+01, 1.33366667e+01, 1.55577778e+01,\n",
       "       1.77788889e+01, 2.00000000e+01]),\n",
       "                          'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                     'saga']}],\n",
       "             scoring='balanced_accuracy', verbose=5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The base model we want to test\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# All the parameters we want to test\n",
    "parameters = [{\"C\":np.linspace(0.01,20,10), # linspace will evenly space values between a start and a stop. \n",
    "                                            # In this case 10 values evenly spaced between 0.01 and 20\n",
    "              \"penalty\":[\"l1\",\"l2\"], # All penalties we want to check, we could also add `None` \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}] # The solvers to use \n",
    "                                                                            # (different underlying algorithms, see docs)\n",
    "\n",
    "# Constructing the grid search \"model\"\n",
    "grid_search = GridSearchCV(estimator=model,             # The base model\n",
    "                           cv=5,                        # Number of cross fold validations\n",
    "                           param_grid=parameters,       # Different parameters to test\n",
    "                           n_jobs=-1,                   # Number of threads to use (-1: all)\n",
    "                           verbose=5,                   # How much information do we want to show? See docs for more info\n",
    "                           scoring=\"balanced_accuracy\") # What score will the model be evaluated on?\n",
    "                                                        # See: https://scikit-learn.org/stable/modules/classes.html?highlight=metric#module-sklearn.metrics\n",
    "# Fit the training data\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: 0.8400000000000001\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "{'C': 2.231111111111111, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=2.231111111111111, max_iter=1000, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Print the score on test set (best model of our grid search)\n",
    "print(f\"Score of best model: {grid_search.score(X_test,y_test)}\")\n",
    "\n",
    "# Predict values for test set for best model\n",
    "y_pred=grid_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "# What where the best parameters for out model?\n",
    "print(\"\\nBest parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.752 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.752 total time=   0.1s\n",
      "[CV 1/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.711 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.596 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.751 total time=   0.2s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.3s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=2.231111111111111, penalty=l2, solver=liblinear;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END C=2.231111111111111, penalty=l2, solver=liblinear;, score=0.851 total time=   0.0s\n",
      "[CV 5/5] END C=2.231111111111111, penalty=l2, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END C=2.231111111111111, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=2.231111111111111, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l2, solver=newton-cg;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=4.452222222222222, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=4.452222222222222, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END C=4.452222222222222, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=4.452222222222222, penalty=l2, solver=lbfgs;, score=0.794 total time=   0.2s\n",
      "[CV 2/5] END C=4.452222222222222, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.2s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l1, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l2, solver=lbfgs;, score=0.794 total time=   0.2s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.2s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=6.673333333333333, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END C=6.673333333333333, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=6.673333333333333, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=6.673333333333333, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=6.673333333333333, penalty=l2, solver=liblinear;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=11.115555555555554, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=11.115555555555554, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=11.115555555555554, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l2, solver=sag;, score=0.733 total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l2, solver=sag;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l2, solver=lbfgs;, score=0.794 total time=   0.3s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.3s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 2/5] END C=20.0, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=20.0, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=20.0, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=20.0, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END ..C=20.0, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.3s\n",
      "[CV 2/5] END ..C=20.0, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.2s\n",
      "[CV 3/5] END ..C=20.0, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END ..C=20.0, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.2s\n",
      "[CV 4/5] END C=1.7443163170257614, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=1.7443163170257614, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.2s\n",
      "[CV 4/5] END C=17.389978476190176, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=13.336666666666666, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.2s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l2, solver=sag;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 3/5] END C=20.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=20.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=20.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=20.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=20.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=20.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=20.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=20.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=20.0, penalty=l1, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=20.0, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=20.0, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=20.0, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=20.0, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END ......C=20.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=20.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=20.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=20.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=20.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=20.0, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ...C=20.0, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END ...C=20.0, penalty=l1, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END ...C=20.0, penalty=l1, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END ...C=20.0, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=20.0, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END ....C=20.0, penalty=l2, solver=sag;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END ....C=20.0, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END ....C=20.0, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END ...C=20.0, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END ...C=20.0, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 4/5] END ...C=20.0, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END C=1.7443163170257614, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 1/5] END C=17.389978476190176, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 1/5] END C=15.742166818743842, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 4/5] END C=15.742166818743842, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END C=18.002243328281555, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=1.2481519021531595, penalty=l2, solver=lbfgs;, score=0.882 total time=   0.2s\n",
      "[CV 2/5] END C=14.221735581493547, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 1/5] END C=15.428174666410962, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 4/5] END C=15.428174666410962, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=9.200196819034803, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END C=7.688617559091611, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 5/5] END C=7.688617559091611, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=15.97205410654834, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=5.52048034617962, penalty=l1, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 4/5] END C=5.52048034617962, penalty=l1, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=4.068467807480122, penalty=l2, solver=newton-cg;, score=0.863 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=11.115555555555554, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=11.115555555555554, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=11.115555555555554, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l1, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l2, solver=newton-cg;, score=0.816 total time=   0.0s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l2, solver=newton-cg;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END C=13.336666666666666, penalty=l2, solver=newton-cg;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=13.336666666666666, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END C=13.336666666666666, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=13.336666666666666, penalty=l2, solver=lbfgs;, score=0.794 total time=   0.2s\n",
      "[CV 2/5] END C=13.336666666666666, penalty=l2, solver=lbfgs;, score=0.769 total time=   0.3s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15.557777777777778, penalty=l1, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l1, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 2/5] END C=15.557777777777778, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=15.557777777777778, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=15.557777777777778, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=15.557777777777778, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l1, solver=liblinear;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l1, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l1, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l2, solver=lbfgs;, score=0.816 total time=   0.2s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l2, solver=lbfgs;, score=0.808 total time=   0.3s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l2, solver=lbfgs;, score=0.859 total time=   0.2s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.3s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.1s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 3/5] END ...C=20.0, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 1/5] END C=1.7443163170257614, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 3/5] END C=17.389978476190176, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=15.742166818743842, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 5/5] END C=15.742166818743842, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=18.002243328281555, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 1/5] END C=1.2481519021531595, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 5/5] END C=1.2481519021531595, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.3s\n",
      "[CV 4/5] END C=14.221735581493547, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.4s\n",
      "[CV 5/5] END C=15.428174666410962, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=9.200196819034803, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=7.688617559091611, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=7.93199040930543, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END C=15.97205410654834, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=5.52048034617962, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 2/5] END C=13.34307648422073, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 2/5] END C=3.3972991985899124, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=3.3972991985899124, penalty=l1, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=3.3972991985899124, penalty=l1, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END C=3.3972991985899124, penalty=l1, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=14.915684384833243, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.4s\n",
      "[CV 2/5] END C=14.915684384833243, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=5.9841839815468765, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=5.9841839815468765, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.5s\n",
      "[CV 5/5] END C=5.9841839815468765, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.4s\n",
      "[CV 1/5] END C=16.484540518109235, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 3/5] END C=9.229142889759606, penalty=l1, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=9.229142889759606, penalty=l1, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=9.229142889759606, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=10.715413693006886, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 4/5] END C=16.705122136396536, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=16.705122136396536, penalty=l2, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 1/5] END C=15.37131431755563, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=15.37131431755563, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 1/5] END C=2.772751434512769, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.772751434512769, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.772751434512769, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.772751434512769, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.772751434512769, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=16.96663788852433, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=16.96663788852433, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 3/5] END C=16.96663788852433, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=7.8626369591285385, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=7.8626369591285385, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=19.631138422565705, penalty=l2, solver=saga;, score=0.706 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=17.77888888888889, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l2, solver=sag;, score=0.733 total time=   0.1s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l2, solver=sag;, score=0.672 total time=   0.1s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l2, solver=sag;, score=0.812 total time=   0.1s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l2, solver=sag;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l2, solver=sag;, score=0.756 total time=   0.1s\n",
      "[CV 1/5] END C=17.77888888888889, penalty=l2, solver=saga;, score=0.689 total time=   0.1s\n",
      "[CV 2/5] END C=17.77888888888889, penalty=l2, solver=saga;, score=0.614 total time=   0.1s\n",
      "[CV 3/5] END C=17.77888888888889, penalty=l2, solver=saga;, score=0.751 total time=   0.1s\n",
      "[CV 4/5] END C=17.77888888888889, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=17.77888888888889, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 1/5] END C=20.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=20.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=20.0, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.2s\n",
      "[CV 1/5] END C=20.0, penalty=l2, solver=liblinear;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END C=20.0, penalty=l2, solver=liblinear;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END C=20.0, penalty=l2, solver=liblinear;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END C=20.0, penalty=l2, solver=liblinear;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=20.0, penalty=l2, solver=liblinear;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END ....C=20.0, penalty=l2, solver=sag;, score=0.733 total time=   0.0s\n",
      "[CV 2/5] END ....C=20.0, penalty=l2, solver=sag;, score=0.672 total time=   0.0s\n",
      "[CV 5/5] END ...C=20.0, penalty=l2, solver=saga;, score=0.716 total time=   0.1s\n",
      "[CV 3/5] END C=1.7443163170257614, penalty=l2, solver=lbfgs;, score=0.882 total time=   0.3s\n",
      "[CV 2/5] END C=17.389978476190176, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.1s\n",
      "[CV 5/5] END C=17.389978476190176, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.4s\n",
      "[CV 1/5] END C=18.002243328281555, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=18.002243328281555, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.5s\n",
      "[CV 4/5] END C=1.2481519021531595, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END C=14.221735581493547, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=14.221735581493547, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=15.428174666410962, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END C=9.200196819034803, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 4/5] END C=9.200196819034803, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=7.688617559091611, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=7.93199040930543, penalty=l1, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 4/5] END C=7.93199040930543, penalty=l1, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END C=15.97205410654834, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 1/5] END C=5.52048034617962, penalty=l1, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 3/5] END C=5.52048034617962, penalty=l1, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 1/5] END C=4.068467807480122, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=4.068467807480122, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=4.068467807480122, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=13.34307648422073, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 3/5] END C=14.075229917369066, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=14.075229917369066, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END C=8.921481440529929, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.4s\n",
      "[CV 4/5] END C=8.921481440529929, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=3.272742565761476, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.272742565761476, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.272742565761476, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.272742565761476, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=15.140034082509764, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=15.140034082509764, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=15.140034082509764, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.5s\n",
      "[CV 4/5] END C=15.140034082509764, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END C=16.484540518109235, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.1s\n",
      "[CV 3/5] END C=16.484540518109235, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=16.484540518109235, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=16.484540518109235, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END C=10.715413693006886, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 3/5] END C=10.715413693006886, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.4s\n",
      "[CV 4/5] END C=10.715413693006886, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=10.715413693006886, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=16.96663788852433, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=16.96663788852433, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=18.842806394863995, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=18.842806394863995, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=5.117768433790037, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=5.117768433790037, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.1s\n",
      "[CV 4/5] END C=5.117768433790037, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=5.117768433790037, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 5/5] END C=5.495901131303996, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=19.809993743648796, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=19.809993743648796, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=19.809993743648796, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END C=19.286433408876103, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=19.286433408876103, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=19.286433408876103, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=18.824844318102194, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 1/5] END C=15.494393350163492, penalty=l2, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=15.494393350163492, penalty=l2, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=15.494393350163492, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=15.494393350163492, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END C=15.698639284296076, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=15.698639284296076, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=15.698639284296076, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=13.34307648422073, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END C=14.075229917369066, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=14.075229917369066, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END C=14.075229917369066, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=8.921481440529929, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.4s\n",
      "[CV 2/5] END C=8.921481440529929, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 5/5] END C=14.915684384833243, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=3.272742565761476, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=15.140034082509764, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=12.644121640704567, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END C=12.644121640704567, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.4s\n",
      "[CV 3/5] END C=12.644121640704567, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.4s\n",
      "[CV 1/5] END C=6.764383313906564, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=6.764383313906564, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=6.764383313906564, penalty=l2, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=6.764383313906564, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END C=10.530354316555139, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=10.530354316555139, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=9.229142889759606, penalty=l1, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=9.229142889759606, penalty=l1, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 1/5] END C=18.22433682709568, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=18.22433682709568, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=18.22433682709568, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=18.22433682709568, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=18.22433682709568, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=16.705122136396536, penalty=l2, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END C=16.705122136396536, penalty=l2, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END C=16.705122136396536, penalty=l2, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 2/5] END C=13.640943933144442, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=13.640943933144442, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=13.640943933144442, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=13.640943933144442, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 2/5] END C=17.926194318727177, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=17.926194318727177, penalty=l1, solver=liblinear;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=17.926194318727177, penalty=l1, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=17.926194318727177, penalty=l1, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=19.199836170225222, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=19.199836170225222, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=19.199836170225222, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=19.199836170225222, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=19.199836170225222, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=7.8626369591285385, penalty=l2, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=7.8626369591285385, penalty=l2, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=7.8626369591285385, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 3/5] END C=19.631138422565705, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=19.631138422565705, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=19.631138422565705, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=5.117768433790037, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=15.53514882903446, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=15.53514882903446, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=15.53514882903446, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 1/5] END C=0.03521073895394244, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=18.780051409977816, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 2/5] END C=18.780051409977816, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=18.780051409977816, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=18.780051409977816, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 3/5] END C=7.550365868868934, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=7.550365868868934, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=7.550365868868934, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=15.698639284296076, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END C=16.80941010007735, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 3/5] END C=16.80941010007735, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=16.80941010007735, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=16.80941010007735, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=16.736587886891815, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=16.736587886891815, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=16.736587886891815, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=4.798379819076986, penalty=l2, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 4/5] END C=13.40980978913893, penalty=l1, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=13.40980978913893, penalty=l1, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=18.27923535881929, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=18.27923535881929, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=8.263015288234637, penalty=l2, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END C=8.263015288234637, penalty=l2, solver=sag;, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END C=8.263015288234637, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=8.263015288234637, penalty=l2, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 3/5] END C=9.253178136524854, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=9.253178136524854, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=9.253178136524854, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=8.060215726101491, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.970783881311346, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=15.163860426647611, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=15.163860426647611, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=15.163860426647611, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END C=12.829793870299891, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=12.829793870299891, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=12.829793870299891, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=19.631138422565705, penalty=l2, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 5/5] END C=7.889517488113152, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=8.352216018299833, penalty=l2, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END C=8.352216018299833, penalty=l2, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END C=8.352216018299833, penalty=l2, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 2/5] END C=0.03521073895394244, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.03521073895394244, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.03521073895394244, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.03521073895394244, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.495901131303996, penalty=l1, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=5.495901131303996, penalty=l1, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=5.495901131303996, penalty=l1, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=5.495901131303996, penalty=l1, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END C=19.809993743648796, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=19.809993743648796, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=19.286433408876103, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=19.286433408876103, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 5/5] END C=18.780051409977816, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=4.793267089359397, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=4.793267089359397, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=4.793267089359397, penalty=l2, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=4.793267089359397, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=4.793267089359397, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=2.5972457437010363, penalty=l2, solver=saga;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END C=2.5972457437010363, penalty=l2, solver=saga;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END C=2.5972457437010363, penalty=l2, solver=saga;, score=0.765 total time=   0.0s\n",
      "[CV 4/5] END C=2.5972457437010363, penalty=l2, solver=saga;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=2.5972457437010363, penalty=l2, solver=saga;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END C=15.893663716688359, penalty=l2, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=15.893663716688359, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=15.893663716688359, penalty=l2, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=15.893663716688359, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=15.893663716688359, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END C=15.494393350163492, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=8.240987563440592, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=8.240987563440592, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=8.240987563440592, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END C=13.742306138586343, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=13.742306138586343, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=13.742306138586343, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=13.742306138586343, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=13.742306138586343, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.044905081361065184, penalty=l2, solver=saga;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END C=0.044905081361065184, penalty=l2, solver=saga;, score=0.627 total time=   0.0s\n",
      "[CV 3/5] END C=0.044905081361065184, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=0.044905081361065184, penalty=l2, solver=saga;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END C=0.044905081361065184, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=15.313254368414764, penalty=l2, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END C=15.313254368414764, penalty=l2, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END C=15.802086221296248, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=15.802086221296248, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=15.802086221296248, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=15.802086221296248, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END C=17.32269280418912, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=17.32269280418912, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=16.736587886891815, penalty=l2, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=16.736587886891815, penalty=l2, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END C=4.798379819076986, penalty=l2, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=4.798379819076986, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=4.798379819076986, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=4.798379819076986, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=0.11072094459744107, penalty=l1, solver=saga;, score=0.725 total time=   0.2s\n",
      "[CV 2/5] END C=0.11072094459744107, penalty=l1, solver=saga;, score=0.608 total time=   0.1s\n",
      "[CV 3/5] END C=0.11072094459744107, penalty=l1, solver=saga;, score=0.745 total time=   0.1s\n",
      "[CV 4/5] END C=0.11072094459744107, penalty=l1, solver=saga;, score=0.780 total time=   0.1s\n",
      "[CV 2/5] END C=8.060215726101491, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=8.060215726101491, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=8.060215726101491, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=8.060215726101491, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.970783881311346, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.1s\n",
      "[CV 2/5] END C=2.970783881311346, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END C=2.970783881311346, penalty=l2, solver=newton-cg;, score=0.882 total time=   0.1s\n",
      "[CV 4/5] END C=2.970783881311346, penalty=l2, solver=newton-cg;, score=0.820 total time=   0.1s\n",
      "[CV 4/5] END C=15.163860426647611, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=15.163860426647611, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=6.7558861812514905, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=6.7558861812514905, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 5/5] END C=14.308637671875227, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 1/5] END C=2.0186800267375924, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=2.0186800267375924, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=2.0186800267375924, penalty=l2, solver=lbfgs;, score=0.882 total time=   0.3s\n",
      "[CV 3/5] END C=7.760569292532905, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=7.760569292532905, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=7.760569292532905, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=0.9756486104054896, penalty=l2, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 4/5] END C=12.73070702272779, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=12.73070702272779, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=14.05411347674763, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=15.742166818743842, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=18.002243328281555, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.5s\n",
      "[CV 2/5] END C=1.2481519021531595, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.4s\n",
      "[CV 3/5] END C=14.221735581493547, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 2/5] END C=15.428174666410962, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=9.200196819034803, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 1/5] END C=12.453417656394889, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=12.453417656394889, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=12.453417656394889, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=12.453417656394889, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=12.453417656394889, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=7.688617559091611, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 1/5] END C=7.93199040930543, penalty=l1, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 3/5] END C=7.93199040930543, penalty=l1, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 1/5] END C=15.97205410654834, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=15.97205410654834, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END C=4.068467807480122, penalty=l2, solver=newton-cg;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=13.34307648422073, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=13.34307648422073, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 5/5] END C=8.921481440529929, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 1/5] END C=3.3972991985899124, penalty=l1, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=14.915684384833243, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=14.915684384833243, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END C=12.644121640704567, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=12.644121640704567, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=5.9841839815468765, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.5s\n",
      "[CV 2/5] END C=5.9841839815468765, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.4s\n",
      "[CV 5/5] END C=6.764383313906564, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=10.530354316555139, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=10.530354316555139, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=10.530354316555139, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.4s\n",
      "[CV 3/5] END C=15.37131431755563, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.4s\n",
      "[CV 4/5] END C=15.37131431755563, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=15.37131431755563, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=13.640943933144442, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 3/5] END C=18.842806394863995, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=18.842806394863995, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=18.842806394863995, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=17.926194318727177, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=7.889517488113152, penalty=l1, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 2/5] END C=7.889517488113152, penalty=l1, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=7.889517488113152, penalty=l1, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=7.889517488113152, penalty=l1, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 4/5] END C=8.352216018299833, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=8.352216018299833, penalty=l2, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 1/5] END C=15.53514882903446, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END C=15.53514882903446, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 2/5] END C=18.824844318102194, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=18.824844318102194, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=18.824844318102194, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=18.824844318102194, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END C=8.240987563440592, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=8.240987563440592, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=7.550365868868934, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=7.550365868868934, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=15.313254368414764, penalty=l2, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END C=15.313254368414764, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=15.313254368414764, penalty=l2, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 1/5] END C=16.80941010007735, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=15.802086221296248, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=6.105919643059513, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=6.105919643059513, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=6.105919643059513, penalty=l2, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END C=13.440951079489377, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=13.440951079489377, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 3/5] END C=13.440951079489377, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=13.440951079489377, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END C=7.247436169975049, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=7.247436169975049, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=9.253178136524854, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END C=9.253178136524854, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 1/5] END C=14.308637671875227, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=14.308637671875227, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 3/5] END C=14.308637671875227, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=14.308637671875227, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 4/5] END C=3.5436347335082927, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.2s\n",
      "[CV 5/5] END C=3.5436347335082927, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=7.760569292532905, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=7.760569292532905, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=14.05411347674763, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=14.05411347674763, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=14.05411347674763, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=12.882547968365342, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=12.882547968365342, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.1s\n",
      "[CV 3/5] END C=12.882547968365342, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=12.882547968365342, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=12.882547968365342, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=4.630697369104716, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "35 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.82611765 0.82211765 0.82211765 0.82211765 0.82611765 0.82211765\n",
      " 0.82603922 0.82211765 0.82996078 0.81819608 0.73160784 0.82603922\n",
      " 0.73160784 0.81419608 0.82211765 0.82996078 0.82211765 0.83011765\n",
      " 0.82211765        nan 0.81819608 0.82211765 0.81819608 0.82603922\n",
      " 0.81819608 0.82211765 0.73160784 0.81427451        nan 0.77498039\n",
      " 0.82211765 0.82211765        nan 0.82603922 0.82211765 0.82211765\n",
      " 0.82996078 0.73160784 0.73160784 0.81819608 0.73160784 0.77498039\n",
      " 0.82603922        nan 0.73160784 0.82996078 0.82603922 0.82603922\n",
      " 0.82211765 0.83388235 0.73160784 0.82603922 0.73160784 0.82211765\n",
      " 0.82211765 0.82603922        nan 0.72760784 0.77498039 0.82603922\n",
      " 0.82211765 0.81819608 0.82996078 0.77498039 0.82603922 0.82996078\n",
      " 0.73160784 0.73160784 0.82211765 0.82211765 0.82996078 0.77498039\n",
      " 0.71568627 0.81819608 0.82211765        nan 0.81811765 0.82996078\n",
      " 0.81819608 0.82211765 0.82603922 0.82611765 0.73160784 0.82996078\n",
      " 0.81419608 0.81811765 0.82211765 0.77105882 0.82603922 0.82211765\n",
      " 0.82996078 0.82211765 0.82211765 0.81819608 0.82996078        nan\n",
      " 0.82211765 0.82211765 0.81419608 0.82603922]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f63f5b4ae70&gt;,\n",
       "                                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;,\n",
       "                                                    &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "                                        {&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f643750f0b0&gt;,\n",
       "                                         &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]}],\n",
       "                   verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f63f5b4ae70&gt;,\n",
       "                                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;liblinear&#x27;,\n",
       "                                                    &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "                                        {&#x27;C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f643750f0b0&gt;,\n",
       "                                         &#x27;penalty&#x27;: [&#x27;l2&#x27;],\n",
       "                                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]}],\n",
       "                   verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions=[{'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f63f5b4ae70>,\n",
       "                                         'penalty': ['l1', 'l2'],\n",
       "                                         'solver': ['newton-cg', 'liblinear',\n",
       "                                                    'sag', 'saga']},\n",
       "                                        {'C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f643750f0b0>,\n",
       "                                         'penalty': ['l2'],\n",
       "                                         'solver': ['lbfgs']}],\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# The base models\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# You can also evaluate different things for different models.\n",
    "# You can add in seperate parameters that can be combined like this: paramaters=[{Set 1 of params},{Set 2 of params}]\n",
    "# Note that in grid search we got a lot of errors, mainly complaining that \"lbfgs\" solver cannot use L1 regularisation.\n",
    "# Here we removed this solver from the first set and added in another set of params, with only lbfgs and L2, but still \n",
    "# changing the C value!\n",
    "parameters = [\n",
    "              #Set 1\n",
    "              {\"C\":uniform(0.01,20),# Uniform: a uniform distribution of values between a minimum and maximum. Needed for\n",
    "                                    # the random search\n",
    "              \"penalty\":[\"l1\",\"l2\"],\n",
    "              \"solver\":[\"newton-cg\", \"liblinear\", \"sag\", \"saga\"]},\n",
    "    \n",
    "              #Set 2\n",
    "              {\"C\":uniform(0.01,20),\n",
    "              \"penalty\":[\"l2\"],\n",
    "              \"solver\":[\"lbfgs\"]}\n",
    "             ]\n",
    "\n",
    "# Number of models (before CV) to evaluate\n",
    "n_iter_search = 100\n",
    "\n",
    "# The random search \"model\", similar to the grid search\n",
    "random_search = RandomizedSearchCV(estimator=model,\n",
    "                                   cv=5,\n",
    "                                   param_distributions=parameters,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=5)\n",
    "# Fit on the training set\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: 0.84\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "{'C': 4.793267089359397, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=4.793267089359397, max_iter=1000, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Print score of the best model on test set\n",
    "print(f\"Score of best model: {random_search.score(X_test,y_test)}\")\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred=random_search.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "# Show the best classifier parameters\n",
    "print(\"\\nBest parameters:\")\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-optimize) (1.3.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-optimize) (23.12.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-optimize) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-optimize) (1.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sed -i 's/np.int/int/g' '~/miniconda3/envs/bit07/lib/python3.12/site-packages/skopt/space/transformers.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END C=15.698639284296076, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END C=6.105919643059513, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=6.105919643059513, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=15.197738803615305, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=15.197738803615305, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=15.197738803615305, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=15.197738803615305, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=15.197738803615305, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=18.013455358338216, penalty=l2, solver=sag;, score=0.745 total time=   0.0s\n",
      "[CV 2/5] END C=18.013455358338216, penalty=l2, solver=sag;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END C=18.013455358338216, penalty=l2, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END C=18.013455358338216, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=18.013455358338216, penalty=l2, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 5/5] END C=13.440951079489377, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 1/5] END C=17.32269280418912, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=17.32269280418912, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=17.32269280418912, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END C=10.551515155142814, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=10.551515155142814, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=10.551515155142814, penalty=l1, solver=liblinear;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=10.551515155142814, penalty=l1, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=10.551515155142814, penalty=l1, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=13.40980978913893, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=13.40980978913893, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=13.40980978913893, penalty=l1, solver=liblinear;, score=0.863 total time=   0.0s\n",
      "[CV 3/5] END C=18.27923535881929, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=18.27923535881929, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=18.27923535881929, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=8.263015288234637, penalty=l2, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 5/5] END C=0.11072094459744107, penalty=l1, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=7.247436169975049, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=7.247436169975049, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=7.247436169975049, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 3/5] END C=6.7558861812514905, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=6.7558861812514905, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=6.7558861812514905, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 1/5] END C=12.829793870299891, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 4/5] END C=2.0186800267375924, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=2.0186800267375924, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.1s\n",
      "[CV 1/5] END C=2.06602693575466, penalty=l2, solver=saga;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END C=2.06602693575466, penalty=l2, solver=saga;, score=0.627 total time=   0.0s\n",
      "[CV 5/5] END C=4.12279741348298, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=3.5436347335082927, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=3.5436347335082927, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=3.5436347335082927, penalty=l2, solver=lbfgs;, score=0.882 total time=   0.2s\n",
      "[CV 2/5] END C=0.9756486104054896, penalty=l2, solver=sag;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END C=0.9756486104054896, penalty=l2, solver=sag;, score=0.804 total time=   0.1s\n",
      "[CV 4/5] END C=0.9756486104054896, penalty=l2, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END C=0.9756486104054896, penalty=l2, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=16.159706359049185, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=12.73070702272779, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=12.73070702272779, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=12.73070702272779, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=5.43730221983585, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=5.43730221983585, penalty=l2, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=9.970557453424936, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=9.970557453424936, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=9.970557453424936, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=9.970557453424936, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=9.970557453424936, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=19.470212116879782, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=19.470212116879782, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=19.470212116879782, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=19.470212116879782, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=19.470212116879782, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10.402566338661776, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=10.402566338661776, penalty=l1, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=10.402566338661776, penalty=l1, solver=liblinear;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=10.402566338661776, penalty=l1, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=10.402566338661776, penalty=l1, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=14.103183484163825, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=14.103183484163825, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=14.103183484163825, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.1s\n",
      "[CV 2/5] END C=11.377722775862777, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=11.377722775862777, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END C=11.377722775862777, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 3/5] END C=12.249529482295433, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END C=13.497926770277841, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=13.497926770277841, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=6.0932586202892285, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=16.126441156112087, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END C=16.126441156112087, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=13.454275962478688, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END .C=4.712691915763278, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 5/5] END .C=4.712691915763278, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END ...C=9.286317366777496, solver=sag;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END ...C=9.286317366777496, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END .C=1.4407972350433607, solver=saga;, score=0.840 total time=   0.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END C=12.829793870299891, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END C=2.06602693575466, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 4/5] END C=2.06602693575466, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 5/5] END C=2.06602693575466, penalty=l2, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END C=13.75394438576825, penalty=l2, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=13.75394438576825, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=13.75394438576825, penalty=l2, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=13.75394438576825, penalty=l2, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=13.75394438576825, penalty=l2, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=4.12279741348298, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=4.12279741348298, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=4.12279741348298, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=4.12279741348298, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.2s\n",
      "[CV 1/5] END C=16.159706359049185, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END C=16.159706359049185, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=16.159706359049185, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 4/5] END C=16.159706359049185, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END C=17.448461982218372, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 2/5] END C=17.448461982218372, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=17.448461982218372, penalty=l2, solver=lbfgs;, score=0.863 total time=   0.3s\n",
      "[CV 4/5] END C=17.448461982218372, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 4/5] END C=11.377722775862777, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END C=12.249529482295433, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=12.249529482295433, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=13.497926770277841, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=6.0932586202892285, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=16.126441156112087, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=13.454275962478688, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END .C=4.712691915763278, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 3/5] END ...C=9.286317366777496, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END .C=1.4407972350433607, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 2/5] END ..C=2.4083387072729074, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END ..C=3.5385061539643416, solver=sag;, score=0.745 total time=   0.2s\n",
      "[CV 3/5] END ..........C=20.0, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=0.026725010470457708, solver=liblinear;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END ..........C=20.0, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END ..........C=20.0, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END ..........C=20.0, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END ...............C=20.0, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 1/5] END ..........C=20.0, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END ..........C=20.0, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END ..............C=20.0, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END ..........C=20.0, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=8.039264567005931, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=16.550613180688927, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END C=10.085433193287235, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 2/5] END C=5.691467825636919, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=6.454603205526992, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END C=6.454603205526992, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.02166925541131134, solver=lbfgs;, score=0.820 total time=   0.1s\n",
      "[CV 2/5] END C=17.243758324861023, solver=newton-cg;, score=0.804 total time=   0.1s\n",
      "[CV 3/5] END C=5.948742870369735, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=2.5747870961957116, solver=newton-cg;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ..C=16.616291763962167, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 2/5] END .C=11.292914181304175, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=0.013688689476045145, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.9946367561604625, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END .C=13.24140486293194, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=14.373276929614617, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END C=3.835910573675884, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=4.0126635182225785, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=4.022500630686687, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=4.022500630686687, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .C=7.188936629436428, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END C=10.050295852083554, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=10.050295852083554, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.9610501204468207, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=18.479710403404912, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=18.479710403404912, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=4.341632290304508, solver=newton-cg;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=3.145805569702704, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=2.0419094063959684, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=10.296003532481143, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=2.9122308802558963, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END .C=18.24761082473157, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END C=2.9759476652717214, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=2.9759476652717214, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END .C=6.5463330469983365, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 3/5] END C=2.7620026721006545, solver=lbfgs;, score=0.882 total time=   0.2s\n",
      "[CV 2/5] END C=3.0149578917139332, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=8.331233729582284, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=8.331233729582284, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.012884762282951, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=18.69147625083277, solver=newton-cg;, score=0.863 total time=   0.1s\n",
      "[CV 3/5] END C=15.560704471069057, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END C=3.010552167954566, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.010194458835905, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.010194458835905, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END .C=14.746438043193816, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END C=3.008092838411702, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.008092838411702, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=11.679084209951919, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END ................C=20.0, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END C=3.007183235241122, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.007138392127487, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END C=14.05411347674763, penalty=l2, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=17.448461982218372, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.3s\n",
      "[CV 1/5] END C=5.43730221983585, penalty=l2, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=5.43730221983585, penalty=l2, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=5.43730221983585, penalty=l2, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 4/5] END C=14.103183484163825, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=14.103183484163825, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=4.630697369104716, penalty=l2, solver=lbfgs;, score=0.804 total time=   0.3s\n",
      "[CV 2/5] END C=4.630697369104716, penalty=l2, solver=lbfgs;, score=0.784 total time=   0.3s\n",
      "[CV 2/5] END C=12.249529482295433, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=13.497926770277841, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END C=6.0932586202892285, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=6.0932586202892285, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=16.126441156112087, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END C=13.454275962478688, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 3/5] END .C=4.712691915763278, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END ...C=9.286317366777496, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 1/5] END .C=1.4407972350433607, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 5/5] END .C=1.4407972350433607, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END ..C=2.4083387072729074, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END ..C=3.5385061539643416, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 5/5] END ..C=3.5385061539643416, solver=sag;, score=0.760 total time=   0.1s\n",
      "[CV 4/5] END ..........C=20.0, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.026725010470457708, solver=liblinear;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ..........C=20.0, solver=newton-cg;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END ..........C=20.0, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END ...............C=20.0, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 5/5] END ...............C=20.0, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END ..........C=20.0, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END ..............C=20.0, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END ..........C=20.0, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END ..........C=20.0, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END C=8.039264567005931, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END C=16.550613180688927, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=16.550613180688927, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=10.085433193287235, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 5/5] END C=10.085433193287235, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=5.691467825636919, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=6.454603205526992, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=0.02166925541131134, solver=lbfgs;, score=0.686 total time=   0.1s\n",
      "[CV 5/5] END C=0.02166925541131134, solver=lbfgs;, score=0.780 total time=   0.1s\n",
      "[CV 4/5] END C=17.243758324861023, solver=newton-cg;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END C=5.948742870369735, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=5.948742870369735, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END C=2.5747870961957116, solver=newton-cg;, score=0.882 total time=   0.0s\n",
      "[CV 5/5] END C=2.5747870961957116, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END ..C=16.616291763962167, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END ..C=16.616291763962167, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END .C=11.292914181304175, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END C=0.013688689476045145, solver=newton-cg;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END C=3.9946367561604625, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 5/5] END C=3.9946367561604625, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .C=13.24140486293194, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END C=14.373276929614617, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.835910573675884, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.835910573675884, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END C=4.0126635182225785, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=4.022500630686687, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END .C=7.188936629436428, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=10.050295852083554, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END C=3.9610501204468207, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=18.479710403404912, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END C=4.341632290304508, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=3.145805569702704, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 5/5] END C=3.145805569702704, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=2.0419094063959684, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10.296003532481143, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END C=2.9122308802558963, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END .C=18.24761082473157, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 3/5] END C=2.9759476652717214, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END .C=6.5463330469983365, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END C=2.7620026721006545, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 1/5] END C=3.0149578917139332, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0149578917139332, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=8.331233729582284, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=3.012884762282951, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.012884762282951, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=18.69147625083277, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=15.560704471069057, solver=newton-cg;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END C=3.010552167954566, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.010194458835905, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END .C=14.746438043193816, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 1/5] END C=3.008092838411702, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END C=11.679084209951919, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END ................C=20.0, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 1/5] END C=3.007183235241122, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.007183235241122, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.007138392127487, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.007117652339376, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END ..C=12.925732881153872, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END C=3.0062790311759007, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.006324815532082, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END C=3.006310135548832, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=3.0063290743451443, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.006350188724178, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.006342945993924, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.006342945993924, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..C=2.4083387072729074, solver=sag;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ..C=2.4083387072729074, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END ..C=3.5385061539643416, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 2/5] END ..........C=20.0, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END ..........C=20.0, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END C=0.026725010470457708, solver=liblinear;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END ..........C=20.0, solver=newton-cg;, score=0.863 total time=   0.1s\n",
      "[CV 4/5] END ..........C=20.0, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END ...............C=20.0, solver=saga;, score=0.765 total time=   0.2s\n",
      "[CV 3/5] END ..........C=20.0, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END ..............C=20.0, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 5/5] END ..............C=20.0, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END ..........C=20.0, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=8.039264567005931, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=8.039264567005931, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=16.550613180688927, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=10.085433193287235, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 1/5] END C=5.691467825636919, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=5.691467825636919, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=6.454603205526992, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.02166925541131134, solver=lbfgs;, score=0.843 total time=   0.2s\n",
      "[CV 3/5] END C=17.243758324861023, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END C=17.243758324861023, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 1/5] END C=5.948742870369735, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=2.5747870961957116, solver=newton-cg;, score=0.784 total time=   0.1s\n",
      "[CV 2/5] END ..C=16.616291763962167, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END .C=11.292914181304175, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 1/5] END C=0.013688689476045145, solver=newton-cg;, score=0.706 total time=   0.0s\n",
      "[CV 5/5] END C=0.013688689476045145, solver=newton-cg;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END C=3.9946367561604625, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END .C=13.24140486293194, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END .C=13.24140486293194, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=14.373276929614617, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=3.835910573675884, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=4.0126635182225785, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=4.0126635182225785, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END C=4.022500630686687, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END .C=7.188936629436428, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 5/5] END .C=7.188936629436428, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END C=10.050295852083554, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=3.9610501204468207, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.9610501204468207, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=18.479710403404912, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=4.341632290304508, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 2/5] END C=3.145805569702704, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=2.0419094063959684, solver=liblinear;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END C=2.0419094063959684, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=10.296003532481143, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=10.296003532481143, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=2.9122308802558963, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END .C=18.24761082473157, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 5/5] END .C=18.24761082473157, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=2.9759476652717214, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END .C=6.5463330469983365, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 1/5] END C=2.7620026721006545, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 5/5] END C=2.7620026721006545, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=3.0149578917139332, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=8.331233729582284, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 3/5] END C=3.012884762282951, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=18.69147625083277, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=18.69147625083277, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END C=15.560704471069057, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=15.560704471069057, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.010552167954566, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.010194458835905, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END .C=14.746438043193816, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 5/5] END .C=14.746438043193816, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END C=3.008092838411702, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=11.679084209951919, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 5/5] END C=11.679084209951919, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 4/5] END ................C=20.0, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END ................C=20.0, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END C=3.007183235241122, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.007138392127487, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=3.007117652339376, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.007117652339376, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END ..C=12.925732881153872, solver=sag;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END ..C=12.925732881153872, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END C=3.0062790311759007, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.006324815532082, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.006324815532082, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=3.006310135548832, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.006310135548832, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 2/5] END C=3.0063290743451443, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.006350188724178, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 4/5] END C=3.006342945993924, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.006385211804223, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.006431403424725, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.0064533211448197, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.0064533211448197, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=11.61002936360695, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=3.0058472815616635, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.0058950423735, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=3.0059329969896718, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=3.0059722940772384, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.005896708829168, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=14.744333374568766, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 1/5] END C=3.0053514502711556, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/guest/miniconda3/envs/bit07/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END C=4.630697369104716, penalty=l2, solver=lbfgs;, score=0.820 total time=   0.1s\n",
      "[CV 5/5] END C=4.630697369104716, penalty=l2, solver=lbfgs;, score=0.800 total time=   0.2s\n",
      "[CV 1/5] END C=11.377722775862777, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 4/5] END C=12.249529482295433, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=13.497926770277841, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END C=6.0932586202892285, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=16.126441156112087, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END C=13.454275962478688, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=13.454275962478688, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END .C=4.712691915763278, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END ...C=9.286317366777496, solver=sag;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END .C=1.4407972350433607, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END ..C=2.4083387072729074, solver=sag;, score=0.804 total time=   0.1s\n",
      "[CV 3/5] END ..C=3.5385061539643416, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 1/5] END ..........C=20.0, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=0.026725010470457708, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=0.026725010470457708, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END ..........C=20.0, solver=newton-cg;, score=0.804 total time=   0.1s\n",
      "[CV 2/5] END ..........C=20.0, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END ..........C=20.0, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END ...............C=20.0, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 2/5] END ..........C=20.0, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END ..............C=20.0, solver=lbfgs;, score=0.824 total time=   0.3s\n",
      "[CV 3/5] END ..........C=20.0, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 4/5] END C=8.039264567005931, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END C=16.550613180688927, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=10.085433193287235, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=5.691467825636919, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=6.454603205526992, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END C=0.02166925541131134, solver=lbfgs;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=17.243758324861023, solver=newton-cg;, score=0.824 total time=   0.1s\n",
      "[CV 4/5] END C=5.948742870369735, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=2.5747870961957116, solver=newton-cg;, score=0.804 total time=   0.1s\n",
      "[CV 3/5] END ..C=16.616291763962167, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 3/5] END .C=11.292914181304175, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 5/5] END .C=11.292914181304175, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END C=0.013688689476045145, solver=newton-cg;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=3.9946367561604625, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END .C=13.24140486293194, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 1/5] END C=14.373276929614617, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=14.373276929614617, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.835910573675884, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=4.0126635182225785, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=4.022500630686687, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END .C=7.188936629436428, solver=lbfgs;, score=0.863 total time=   0.1s\n",
      "[CV 1/5] END C=10.050295852083554, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=3.9610501204468207, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=18.479710403404912, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=4.341632290304508, solver=newton-cg;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=4.341632290304508, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.145805569702704, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=2.0419094063959684, solver=liblinear;, score=0.922 total time=   0.0s\n",
      "[CV 2/5] END C=10.296003532481143, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=2.9122308802558963, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=2.9122308802558963, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END .C=18.24761082473157, solver=lbfgs;, score=0.804 total time=   0.2s\n",
      "[CV 2/5] END C=2.9759476652717214, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END .C=6.5463330469983365, solver=saga;, score=0.706 total time=   0.1s\n",
      "[CV 5/5] END .C=6.5463330469983365, solver=saga;, score=0.720 total time=   0.1s\n",
      "[CV 4/5] END C=2.7620026721006545, solver=lbfgs;, score=0.820 total time=   0.2s\n",
      "[CV 3/5] END C=3.0149578917139332, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=8.331233729582284, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END C=3.012884762282951, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=18.69147625083277, solver=newton-cg;, score=0.804 total time=   0.1s\n",
      "[CV 4/5] END C=15.560704471069057, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=3.010552167954566, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.010552167954566, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.010194458835905, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END .C=14.746438043193816, solver=saga;, score=0.627 total time=   0.1s\n",
      "[CV 3/5] END C=3.008092838411702, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=11.679084209951919, solver=lbfgs;, score=0.863 total time=   0.2s\n",
      "[CV 1/5] END ................C=20.0, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 3/5] END C=3.007183235241122, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.007138392127487, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.007117652339376, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END ..C=12.925732881153872, solver=sag;, score=0.745 total time=   0.1s\n",
      "[CV 3/5] END C=3.0062790311759007, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.006324815532082, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.006310135548832, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.0063290743451443, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.006350188724178, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=3.006342945993924, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.006385211804223, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.006431403424725, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.0064533211448197, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=11.61002936360695, solver=newton-cg;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END C=3.0058472815616635, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END C=3.0058950423735, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=3.0059329969896718, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0059722940772384, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.005896708829168, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=14.744333374568766, solver=lbfgs;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END C=3.0053514502711556, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END .C=8.513843226915146, solver=lbfgs;, score=0.824 total time=   0.2s\n",
      "[CV 1/5] END C=3.0028449234814034, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0028449234814034, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 2/5] END C=3.002920199214989, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_iter=100,\n",
       "              n_jobs=-1,\n",
       "              search_spaces=[{&#x27;C&#x27;: Real(low=0.01, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                              &#x27;solver&#x27;: Categorical(categories=(&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;), prior=None)}],\n",
       "              verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_iter=100,\n",
       "              n_jobs=-1,\n",
       "              search_spaces=[{&#x27;C&#x27;: Real(low=0.01, high=20, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                              &#x27;solver&#x27;: Categorical(categories=(&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;), prior=None)}],\n",
       "              verbose=5)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_iter=100,\n",
       "              n_jobs=-1,\n",
       "              search_spaces=[{'C': Real(low=0.01, high=20, prior='uniform', transform='normalize'),\n",
       "                              'solver': Categorical(categories=('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'), prior=None)}],\n",
       "              verbose=5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real,Categorical\n",
    "\n",
    "# The base model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# The parameters\n",
    "parameters = [{\"C\":Real(0.01,20,prior=\"uniform\"), #Instead of uniform, we now need to use Real with prior uniform\n",
    "              \"solver\":Categorical([\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"])}] \n",
    "                      # Instead of normal list, we now need to wrap it into a Categorical\n",
    "    \n",
    "# Number of searches our model is allowed to do\n",
    "n_iter_search = 100\n",
    "\n",
    "# The bayes_search 'model' similar to grid and random search\n",
    "bayes_search = BayesSearchCV(estimator=model,\n",
    "                                   cv=5,\n",
    "                                   search_spaces=parameters,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=5)\n",
    "# Fit on the training data\n",
    "bayes_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: 0.84\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.81      0.88      0.85        25\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.84      0.84        50\n",
      "weighted avg       0.84      0.84      0.84        50\n",
      "\n",
      "\n",
      "Best parameters:\n",
      "OrderedDict({'C': 3.145805569702704, 'solver': 'liblinear'})\n",
      "LogisticRegression(C=3.145805569702704, max_iter=1000, solver='liblinear')\n",
      "[CV 5/5] END C=3.002920199214989, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.002976369284996, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=3.002997697139485, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.002997697139485, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 2/5] END C=15.449609198930672, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.0024380549643004, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.0024277839211266, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0024277839211266, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0025343389321733, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.002638919815575, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.0026180924239605, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.0027580642859646, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.0028489981219257, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.002883621286088, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.002883621286088, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=3.002934646237132, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.003002556372702, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.0030602081110547, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0030602081110547, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.003207949652513, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0031748077727864, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 5/5] END C=3.007138392127487, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.007117652339376, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END ..C=12.925732881153872, solver=sag;, score=0.824 total time=   0.1s\n",
      "[CV 2/5] END C=3.0062790311759007, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.0062790311759007, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.006324815532082, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.006310135548832, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0063290743451443, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 5/5] END C=3.0063290743451443, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=3.006350188724178, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 5/5] END C=3.006350188724178, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END C=3.006342945993924, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.006385211804223, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.006385211804223, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.006431403424725, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END C=3.006431403424725, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0064533211448197, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=11.61002936360695, solver=newton-cg;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=11.61002936360695, solver=newton-cg;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.0058472815616635, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END C=3.0058472815616635, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0058950423735, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END C=3.0058950423735, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 2/5] END C=3.0059329969896718, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.0059329969896718, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0059722940772384, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.005896708829168, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.005896708829168, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=14.744333374568766, solver=lbfgs;, score=0.863 total time=   0.1s\n",
      "[CV 5/5] END C=14.744333374568766, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=3.0053514502711556, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END .C=8.513843226915146, solver=lbfgs;, score=0.863 total time=   0.1s\n",
      "[CV 5/5] END .C=8.513843226915146, solver=lbfgs;, score=0.800 total time=   0.1s\n",
      "[CV 4/5] END C=3.0028449234814034, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.002920199214989, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=3.002976369284996, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.002976369284996, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=3.002997697139485, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=15.449609198930672, solver=liblinear;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END C=3.0024380549643004, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.0024277839211266, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.0025343389321733, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.002638919815575, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.0026180924239605, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.0027580642859646, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0027580642859646, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0028489981219257, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.002883621286088, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.002934646237132, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.003002556372702, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.0030602081110547, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.003207949652513, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.003207949652513, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0031748077727864, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.006385211804223, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.006431403424725, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.0064533211448197, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=11.61002936360695, solver=newton-cg;, score=0.863 total time=   0.0s\n",
      "[CV 3/5] END C=3.0058472815616635, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=3.0058950423735, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.0059329969896718, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.0059722940772384, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.0059722940772384, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.005896708829168, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=14.744333374568766, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 3/5] END C=3.0053514502711556, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END .C=8.513843226915146, solver=lbfgs;, score=0.784 total time=   0.2s\n",
      "[CV 2/5] END C=3.0028449234814034, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.002920199214989, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 2/5] END C=3.002976369284996, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.002997697139485, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END C=15.449609198930672, solver=liblinear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=3.0024380549643004, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.0024380549643004, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0024277839211266, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0025343389321733, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.002638919815575, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 5/5] END C=3.002638919815575, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0026180924239605, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 4/5] END C=3.0027580642859646, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0028489981219257, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.002883621286088, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END C=3.002934646237132, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.003002556372702, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.003002556372702, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.0030602081110547, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=3.003207949652513, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 1/5] END C=3.0031748077727864, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0031748077727864, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 5/5] END C=3.0053514502711556, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END .C=8.513843226915146, solver=lbfgs;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END C=3.0028449234814034, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.002920199214989, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.002976369284996, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 4/5] END C=3.002997697139485, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=15.449609198930672, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=15.449609198930672, solver=liblinear;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=3.0024380549643004, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END C=3.0024277839211266, solver=liblinear;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END C=3.0025343389321733, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0025343389321733, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.002638919815575, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 1/5] END C=3.0026180924239605, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0026180924239605, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=3.0027580642859646, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=3.0028489981219257, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.0028489981219257, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 3/5] END C=3.002883621286088, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 1/5] END C=3.002934646237132, solver=liblinear;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END C=3.002934646237132, solver=liblinear;, score=0.820 total time=   0.0s\n",
      "[CV 4/5] END C=3.003002556372702, solver=liblinear;, score=0.860 total time=   0.0s\n",
      "[CV 3/5] END C=3.0030602081110547, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END C=3.003207949652513, solver=liblinear;, score=0.902 total time=   0.0s\n",
      "[CV 2/5] END C=3.0031748077727864, solver=liblinear;, score=0.824 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# Print the sores of the best model\n",
    "print(f\"Score of best model: {bayes_search.score(X_test,y_test)}\")\n",
    "\n",
    "# Predict the classes of test set\n",
    "y_pred=bayes_search.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#Print the best parameters\n",
    "print(\"\\nBest parameters:\")\n",
    "print(bayes_search.best_params_)\n",
    "print(bayes_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "\n",
    "# Get the probabilities for the grid search from earlier on\n",
    "probs_grid = grid_search.predict_proba(X_test)\n",
    "# Keep only those of the 'true' class, so the second column: [:,1] => all rows, column 1 (zero based so actually second col)\n",
    "preds_grid = probs_grid[:,1]\n",
    "# Calculate false and true positives using this information\n",
    "fpr_grid, tpr_grid, threshold_grid = metrics.roc_curve(y_test, preds_grid)\n",
    "# Calculare Area Under the Curve (AUC)\n",
    "roc_auc_grid = metrics.auc(fpr_grid, tpr_grid)\n",
    "\n",
    "# Do exactly the same for the bayes search model\n",
    "probs_bayes = bayes_search.predict_proba(X_test)\n",
    "preds_bayes = probs_bayes[:,1]\n",
    "fpr_bayes, tpr_bayes, threshold_bayes = metrics.roc_curve(y_test, preds_bayes)\n",
    "roc_auc_bayes = metrics.auc(fpr_bayes, tpr_bayes)\n",
    "\n",
    "# plot the ROC curve, also add a legend, titles and a diagonal dotted line representing 50/50 chance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_grid, tpr_grid, 'b', alpha=0.5, label = 'Grid AUROC = %0.2f' % roc_auc_grid)\n",
    "plt.plot(fpr_bayes, tpr_bayes, 'r', alpha=0.5, label = 'Bayes AUROC = %0.2f' % roc_auc_bayes)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c87a5d71e54ae3adb32547392a29f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='Treshold', max=1.0, step=0.01), Output()), _dom_clas"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive ROC\n",
    "# This roc will show you where we land on the graph if we use a different treshold. So basically how this graph is\n",
    "# constructed.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "Total_positives=sum(y_test)\n",
    "Total_negatives=sum([1 for x in y_test if x==0 ])\n",
    "\n",
    "@interact(Treshold=(0,1,0.01))\n",
    "def drawROC(Treshold=0.5):\n",
    "    probs_bayes = bayes_search.predict_proba(X_test)\n",
    "    preds_bayes = probs_bayes[:,1]\n",
    "    fpr_bayes, tpr_bayes, threshold_bayes = metrics.roc_curve(y_test, preds_bayes)\n",
    "    roc_auc_bayes = metrics.auc(fpr_bayes, tpr_bayes)\n",
    "    \n",
    "    pred_treshold = [0 if x<Treshold else 1 for x in probs_bayes[:,1]]\n",
    "    true_positives = sum([1 for x,y in zip(y_test,pred_treshold) if x==y==1])\n",
    "    true_negatives = sum([1 for x,y in zip(y_test,pred_treshold) if x==y==0])\n",
    "    \n",
    "    print(\"TPR: \",tpr:=true_positives/Total_positives)\n",
    "    print(\"FPR: \",fpr:=1-true_negatives/Total_negatives)\n",
    "    # plot the curve\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr_bayes, tpr_bayes, 'r', alpha=0.5, label = 'Bayes AUC = %0.2f' % roc_auc_bayes)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.scatter(fpr,tpr)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
